{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc1ac4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# √âtape 1 & 2 - Analyse exploratoire + Score m√©tier (projet Home Credit)\n",
    "# Objectif : analyser les donn√©es et cr√©er une fonction m√©tier pour √©valuer un mod√®le de scoring cr√©dit\n",
    "\n",
    "# ----------------------\n",
    "# IMPORT DES LIBRAIRIES\n",
    "# ----------------------\n",
    "import pandas as pd  # gestion des donn√©es\n",
    "import numpy as np  # calculs num√©riques\n",
    "import matplotlib.pyplot as plt  # visualisation simple\n",
    "import seaborn as sns  # visualisation plus avanc√©e\n",
    "import missingno as msno  # visualisation des valeurs manquantes\n",
    "import warnings  # pour cacher les avertissements\n",
    "from sklearn.model_selection import train_test_split  # d√©couper les donn√©es\n",
    "from sklearn.linear_model import LogisticRegression  # mod√®le simple et interpr√©table\n",
    "from sklearn.metrics import confusion_matrix  # √©valuer les erreurs de pr√©diction\n",
    "\n",
    "warnings.filterwarnings('ignore')  # √©viter d'afficher les messages de warning inutiles\n",
    "\n",
    "# -------------------------------------\n",
    "# CHARGEMENT DES DONN√âES\n",
    "# -------------------------------------\n",
    "file_path = \"//content/drive/MyDrive/Master AI Engineer/Colab Notebooks/Projet 4/application_train.csv\"\n",
    "\n",
    "# On essaie d'abord avec une virgule, sinon on essaye avec point-virgule\n",
    "try:\n",
    "    df = pd.read_csv(file_path, sep=\",\", encoding=\"utf-8\", low_memory=False)\n",
    "    if df.shape[1] == 1:\n",
    "        raise ValueError(\"Colonnes mal s√©par√©es\")\n",
    "except:\n",
    "    df = pd.read_csv(file_path, sep=\";\", encoding=\"utf-8\", low_memory=False)\n",
    "\n",
    "# -------------------------------------\n",
    "# ANALYSE EXPLORATOIRE\n",
    "# -------------------------------------\n",
    "print(\"Aper√ßu des donn√©es :\")\n",
    "print(df.head())\n",
    "print(\"\\nDimensions :\", df.shape)\n",
    "print(\"\\nTypes de donn√©es :\")\n",
    "print(df.dtypes.value_counts())\n",
    "print(\"\\nInfos d√©taill√©es :\")\n",
    "df.info()\n",
    "\n",
    "# Valeurs manquantes\n",
    "missing = df.isnull().mean().sort_values(ascending=False) * 100\n",
    "missing = missing[missing > 0]\n",
    "if not missing.empty:\n",
    "    plt.figure(figsize=(10, 12))\n",
    "    missing.plot(kind=\"barh\", title=\"Pourcentage de valeurs manquantes par colonne\")\n",
    "    plt.xlabel(\"Pourcentage de valeurs manquantes\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Aucune valeur manquante d√©tect√©e.\")\n",
    "\n",
    "# Statistiques globales\n",
    "print(\"\\nStatistiques g√©n√©rales :\")\n",
    "print(df.describe().T)\n",
    "\n",
    "# Distribution de la cible (TARGET)\n",
    "if 'TARGET' in df.columns:\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    df['TARGET'].value_counts(normalize=True).plot(kind='bar', color=['skyblue', 'salmon'])\n",
    "    plt.title(\"R√©partition de la variable cible (TARGET)\")\n",
    "    plt.xlabel(\"0 = Bon client, 1 = Mauvais client\")\n",
    "    plt.ylabel(\"Proportion\")\n",
    "    plt.show()\n",
    "\n",
    "# -------------------------------------\n",
    "# FEATURE ENGINEERING - NOUVELLES VARIABLES\n",
    "# -------------------------------------\n",
    "print(\"\\nCr√©ation de nouvelles variables :\")\n",
    "if {'AMT_CREDIT', 'AMT_INCOME_TOTAL'}.issubset(df.columns):\n",
    "    df['CREDIT_INCOME_RATIO'] = df['AMT_CREDIT'] / df['AMT_INCOME_TOTAL']\n",
    "    print(\"CREDIT_INCOME_RATIO ajout√©.\")\n",
    "\n",
    "if {'AMT_ANNUITY', 'AMT_INCOME_TOTAL'}.issubset(df.columns):\n",
    "    df['ANNUITY_INCOME_RATIO'] = df['AMT_ANNUITY'] / df['AMT_INCOME_TOTAL']\n",
    "    print(\"ANNUITY_INCOME_RATIO ajout√©.\")\n",
    "\n",
    "if {'DAYS_EMPLOYED', 'DAYS_BIRTH'}.issubset(df.columns):\n",
    "    df['EMPLOYED_AGE_RATIO'] = df['DAYS_EMPLOYED'] / df['DAYS_BIRTH']\n",
    "    print(\"EMPLOYED_AGE_RATIO ajout√©.\")\n",
    "\n",
    "# -------------------------------------\n",
    "# CORR√âLATION AVEC LA CIBLE\n",
    "# -------------------------------------\n",
    "if 'TARGET' in df.columns:\n",
    "    correlations = df.corr(numeric_only=True)['TARGET'].sort_values(ascending=False)\n",
    "    print(\"\\nTop 10 variables les plus corr√©l√©es positivement avec le d√©faut :\")\n",
    "    print(correlations.head(10))\n",
    "    print(\"\\nTop 10 variables les plus corr√©l√©es n√©gativement avec le d√©faut :\")\n",
    "    print(correlations.tail(10))\n",
    "\n",
    "# -------------------------------------\n",
    "# EXPLORATION DES VARIABLES CAT√âGORIELLES\n",
    "# -------------------------------------\n",
    "print(\"\\nExploration des variables cat√©gorielles :\")\n",
    "cat_cols = df.select_dtypes(include='object').columns\n",
    "for col in cat_cols:\n",
    "    print(f\"\\n{col} :\")\n",
    "    print(df[col].value_counts(dropna=False).head())\n",
    "\n",
    "# -------------------------------------\n",
    "# √âTAPE 2 : SCORING M√âTIER ET SEUIL OPTIMAL\n",
    "# -------------------------------------\n",
    "# Nettoyage simple : suppression des NaN, s√©lection des colonnes num√©riques uniquement\n",
    "# (pour simplifier, on ne conserve ici que les colonnes sans NaN pour ce premier test)\n",
    "\n",
    "df_model = df.dropna()\n",
    "features = ['AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY', 'CREDIT_INCOME_RATIO', 'ANNUITY_INCOME_RATIO', 'EMPLOYED_AGE_RATIO']\n",
    "X = df_model[features]\n",
    "y = df_model['TARGET']\n",
    "\n",
    "# D√©coupage des donn√©es en 80% train / 20% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Mod√®le de r√©gression logistique (mod√®le simple et interpr√©table)\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Pr√©diction des probabilit√©s pour le test\n",
    "y_proba = model.predict_proba(X_test)[:, 1]  # on r√©cup√®re les probabilit√©s d'appartenir √† la classe 1\n",
    "\n",
    "# ------------------\n",
    "# Fonction de co√ªt m√©tier\n",
    "# ------------------\n",
    "def cout_metier(y_true, y_pred, cost_fn=10, cost_fp=1):\n",
    "    \"\"\"Calcule le co√ªt total en fonction du nombre de faux n√©gatifs et faux positifs\"\"\"\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    return cost_fn * fn + cost_fp * fp\n",
    "\n",
    "# ------------------\n",
    "# Fonction pour trouver le meilleur seuil\n",
    "# ------------------\n",
    "def trouver_seuil_optimal(y_true, y_proba, seuils=np.arange(0.1, 0.9, 0.01), cost_fn=10, cost_fp=1):\n",
    "    meilleur_seuil = None\n",
    "    meilleur_cout = float('inf')\n",
    "\n",
    "    for seuil in seuils:\n",
    "        y_pred = (y_proba >= seuil).astype(int)\n",
    "        cout = cout_metier(y_true, y_pred, cost_fn, cost_fp)\n",
    "        if cout < meilleur_cout:\n",
    "            meilleur_cout = cout\n",
    "            meilleur_seuil = seuil\n",
    "\n",
    "    return {\"seuil\": meilleur_seuil, \"co√ªt\": meilleur_cout}\n",
    "\n",
    "# Application sur les r√©sultats\n",
    "resultat = trouver_seuil_optimal(y_test, y_proba)\n",
    "print(f\"\\n‚úÖ Seuil optimal = {resultat['seuil']:.2f}, co√ªt total = {resultat['co√ªt']}\")\n",
    "\n",
    "# Affichage graphique du co√ªt selon le seuil choisi\n",
    "seuils = np.arange(0.1, 0.9, 0.01)\n",
    "costs = [cout_metier(y_test, (y_proba >= s).astype(int)) for s in seuils]\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(seuils, costs, label=\"Co√ªt m√©tier\")\n",
    "plt.axvline(resultat['seuil'], color='red', linestyle='--', label='Seuil optimal')\n",
    "plt.xlabel(\"Seuil de classification\")\n",
    "plt.ylabel(\"Co√ªt total (pond√©r√©)\")\n",
    "plt.title(\"Optimisation du seuil de d√©cision\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ‚úÖ Fin de l'√©tape 2 : mod√®le interpr√©table + seuil optimis√© selon le co√ªt m√©tier\n",
    "\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# √âTAPE 3 ‚Äì Benchmark de mod√®les : R√©gression Logistique vs Random Forest\n",
    "# Objectif : tester plusieurs mod√®les et les comparer en tenant compte :\n",
    "# - du d√©s√©quilibre entre bons et mauvais clients\n",
    "# - du co√ªt m√©tier (FN plus grave que FP)\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "# Import de biblioth√®ques suppl√©mentaires pour cette √©tape\n",
    "from sklearn.ensemble import RandomForestClassifier  # un mod√®le plus complexe que la r√©gression\n",
    "from sklearn.model_selection import cross_val_score  # pour faire de la validation crois√©e\n",
    "from sklearn.pipeline import Pipeline  # permet d‚Äôencha√Æner plusieurs √©tapes dans un m√™me objet\n",
    "from sklearn.preprocessing import StandardScaler  # pour normaliser les donn√©es\n",
    "from sklearn.metrics import roc_auc_score, roc_curve  # m√©triques de performance\n",
    "from imblearn.over_sampling import SMOTE  # technique pour √©quilibrer les classes\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline  # pipeline compatible avec SMOTE\n",
    "\n",
    "# On refait un d√©coupage 80/20 pour bien s√©parer l'entra√Ænement et le test\n",
    "# stratify permet de garder le m√™me % de mauvais clients dans chaque groupe\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Liste des mod√®les qu'on veut comparer\n",
    "# Un mod√®le simple (logistique) et un plus puissant (for√™t al√©atoire)\n",
    "modeles = [\n",
    "    (\"R√©gression Logistique\", LogisticRegression(max_iter=1000)),\n",
    "    (\"Random Forest\", RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "]\n",
    "\n",
    "# On pr√©pare une liste pour stocker les r√©sultats de chaque mod√®le\n",
    "resultats = []\n",
    "\n",
    "# On teste chaque mod√®le un par un\n",
    "for nom_modele, modele in modeles:\n",
    "    # On cr√©e un \"pipeline\" : c‚Äôest un encha√Ænement d‚Äô√©tapes automatiques\n",
    "    # 1. StandardScaler : normalise les donn√©es (utile pour la r√©gression logistique)\n",
    "    # 2. SMOTE : augmente artificiellement les exemples de mauvais clients (classe minoritaire)\n",
    "    # 3. Le mod√®le choisi\n",
    "    pipeline = ImbPipeline(steps=[\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('smote', SMOTE(random_state=42)),\n",
    "        ('model', modele)\n",
    "    ])\n",
    "\n",
    "    # On √©value la performance du mod√®le via une validation crois√©e (5 parties du jeu d'entra√Ænement)\n",
    "    # Cela √©vite de tirer des conclusions trop h√¢tives sur un seul d√©coupage\n",
    "    scores_auc = cross_val_score(pipeline, X_train, y_train, scoring='roc_auc', cv=5)\n",
    "    moyenne_auc = np.mean(scores_auc)  # moyenne des AUC obtenues\n",
    "\n",
    "    # On entra√Æne le pipeline sur tout le jeu d'entra√Ænement\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # On pr√©dit les probabilit√©s pour chaque client du jeu de test\n",
    "    y_proba = pipeline.predict_proba(X_test)[:, 1]  # on garde la proba d‚Äô√™tre un mauvais client (classe 1)\n",
    "\n",
    "    # On cherche le seuil de proba qui minimise notre score m√©tier (FN = 10x FP)\n",
    "    resultat_seuil = trouver_seuil_optimal(y_test, y_proba)\n",
    "\n",
    "    # On transforme les proba en pr√©diction 0 ou 1 avec le bon seuil\n",
    "    y_pred = (y_proba >= resultat_seuil['seuil']).astype(int)\n",
    "\n",
    "    # On mesure la qualit√© globale via l‚ÄôAUC (plus c‚Äôest proche de 1, mieux c‚Äôest)\n",
    "    auc_test = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "    # On enregistre les r√©sultats\n",
    "    resultats.append({\n",
    "        \"Mod√®le\": nom_modele,\n",
    "        \"AUC Test\": round(auc_test, 3),\n",
    "        \"Seuil M√©tier\": round(resultat_seuil['seuil'], 2),\n",
    "        \"Co√ªt M√©tier\": resultat_seuil['co√ªt']\n",
    "    })\n",
    "\n",
    "# On affiche un tableau r√©capitulatif des performances\n",
    "resultats_df = pd.DataFrame(resultats)\n",
    "print(\"\\nüìä R√©sum√© des performances par mod√®le :\")\n",
    "print(resultats_df)\n",
    "\n",
    "# BONUS : on trace la courbe ROC pour le meilleur mod√®le (ici Random Forest)\n",
    "# ROC = Receiver Operating Characteristic\n",
    "# C‚Äôest une courbe qui montre le compromis entre :\n",
    "# - vrai positifs (clients mal class√©s d√©tect√©s)\n",
    "# - faux positifs (bons clients √† qui on refuse √† tort)\n",
    "# 3. On r√©entra√Æne un mod√®le Random Forest sur tout l'ensemble d'entra√Ænement pour l'analyse SHAP\n",
    "# On enl√®ve StandardScaler ici car RandomForest n'en a pas besoin\n",
    "best_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "best_pipeline = ImbPipeline([\n",
    "    ('smote', SMOTE(random_state=42)),  # on garde SMOTE pour √©quilibrer les classes\n",
    "    ('model', best_model)\n",
    "])\n",
    "best_pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_proba_best = best_pipeline.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, _ = roc_curve(y_test, y_proba_best)  # fpr = faux positifs, tpr = vrais positifs\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(fpr, tpr, label=\"ROC - Random Forest\")\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray')  # diagonale : tirage au sort\n",
    "plt.xlabel(\"Taux de faux positifs\")\n",
    "plt.ylabel(\"Taux de vrais positifs\")\n",
    "plt.title(\"Courbe ROC - Random Forest\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ‚úÖ √âtape 3 termin√©e : on a compar√© 2 mod√®les, g√©r√© le d√©s√©quilibre, mesur√© l‚ÄôAUC et le score m√©tier\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# √âTAPE 4 ‚Äì Interpr√©tation du mod√®le avec SHAP (importance globale et locale)\n",
    "# Objectif : expliquer comment le mod√®le prend ses d√©cisions\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "# 1. On importe la librairie SHAP (permet d‚Äôinterpr√©ter comment le mod√®le raisonne)\n",
    "import shap\n",
    "\n",
    "# 2. On r√©entra√Æne un mod√®le Random Forest tout seul, sans pipeline ni SMOTE\n",
    "# Pourquoi ? Parce que SHAP a besoin du mod√®le brut (pas d‚Äôun pipeline) et des donn√©es originales\n",
    "modele_shap = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "modele_shap.fit(X_train, y_train)  # entra√Ænement sur les donn√©es d'entra√Ænement d'origine\n",
    "\n",
    "# 3. On cr√©e un \"explainer\" SHAP adapt√© aux mod√®les d‚Äôarbres (comme RandomForest)\n",
    "explainer = shap.TreeExplainer(modele_shap)\n",
    "\n",
    "# -------------------------------\n",
    "# √©chantillonnage pour acc√©l√©rer le calcul SHAP\n",
    "# On s√©lectionne 200 clients du jeu de test, √ßa suffit pour l‚Äôanalyse globale\n",
    "# Cela √©vite que SHAP prenne plusieurs minutes √† tout calculer\n",
    "X_test_sample_df = X_test.sample(n=200, random_state=42).copy()  # on prend un sous-√©chantillon du test\n",
    "\n",
    "# 4. On calcule les valeurs SHAP avec la nouvelle API\n",
    "shap_values = explainer(X_test_sample_df)\n",
    "\n",
    "# 5. Affichage global des variables les plus influentes\n",
    "shap.summary_plot(shap_values.values, X_test_sample_df, plot_type=\"bar\")\n",
    "\n",
    "#Interpretation locale\n",
    "\n",
    "\n",
    "# Besoin d'aide ici @Gred\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# √âTAPE 5 ‚Äì DummyClassifier + Optimisation Random Forest avec GridSearchCV\n",
    "# Objectif : r√©pondre aux attentes restantes du mentor :\n",
    "# - Ajouter un mod√®le de r√©f√©rence (tr√®s basique) appel√© \"DummyClassifier\"\n",
    "# - Utiliser GridSearchCV pour tester plusieurs combinaisons de param√®tres\n",
    "# - Optimiser le mod√®le en fonction de notre score m√©tier\n",
    "# - Mesurer aussi l'AUC (qualit√© globale) et le temps d'ex√©cution\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "from sklearn.dummy import DummyClassifier  # mod√®le tr√®s simple pour √©tablir une baseline\n",
    "from sklearn.metrics import make_scorer  # pour cr√©er une m√©trique personnalis√©e\n",
    "from sklearn.model_selection import GridSearchCV  # outil pour tester plusieurs r√©glages automatiques\n",
    "import time  # pour chronom√©trer l'entra√Ænement\n",
    "\n",
    "# ‚ûú On commence par un mod√®le de base (Dummy) qui pr√©dit toujours la majorit√©\n",
    "dummy = DummyClassifier(strategy=\"most_frequent\")  # toujours pr√©dire 0\n",
    "dummy.fit(X_train, y_train)\n",
    "y_pred_dummy = dummy.predict(X_test)\n",
    "cout_dummy = cout_metier(y_test, y_pred_dummy)\n",
    "print(f\"\\nüìå Co√ªt m√©tier DummyClassifier (baseline na√Øve) : {cout_dummy}\")\n",
    "\n",
    "# ‚ûú On va maintenant d√©finir une fonction personnalis√©e pour que GridSearch comprenne notre score m√©tier\n",
    "def scoring_metier(y_true, y_proba):\n",
    "    y_pred = (y_proba >= 0.5).astype(int)  # on garde un seuil fixe ici (comme demand√©)\n",
    "    return -cout_metier(y_true, y_pred)  # on inverse car GridSearch cherche √† *maximiser* le score\n",
    "\n",
    "# make_scorer transforme notre fonction en objet compatible avec sklearn\n",
    "scorer = make_scorer(scoring_metier, needs_proba=True)\n",
    "\n",
    "# ‚ûú On d√©finit les param√®tres qu'on veut tester pour la Random Forest\n",
    "param_grid = {\n",
    "    'model__n_estimators': [50, 100],  # nombre d‚Äôarbres dans la for√™t\n",
    "    'model__max_depth': [5, 10, None]  # profondeur maximale des arbres\n",
    "}\n",
    "\n",
    "# ‚ûú Pipeline avec normalisation + SMOTE + RandomForest (comme √† l‚Äô√©tape 3)\n",
    "pipeline = ImbPipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('model', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# ‚ûú On lance GridSearchCV en demandant :\n",
    "# - d‚Äôoptimiser √† la fois notre score m√©tier et l‚ÄôAUC\n",
    "# - de choisir le mod√®le avec le *meilleur score m√©tier*\n",
    "grid = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    scoring={'metier': scorer, 'auc': 'roc_auc'},\n",
    "    refit='metier',\n",
    "    cv=5,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "# ‚ûú On lance l'entra√Ænement complet avec chronom√®tre\n",
    "start = time.time()\n",
    "grid.fit(X_train, y_train)\n",
    "end = time.time()\n",
    "\n",
    "# ‚ûú Affichage des meilleurs param√®tres et scores associ√©s\n",
    "print(\"\\n‚úÖ Meilleurs param√®tres trouv√©s par GridSearch :\")\n",
    "print(grid.best_params_)\n",
    "print(f\"Score m√©tier moyen (sur le train cross-valid√©) : {-grid.best_score_:.0f}\")\n",
    "print(f\"Temps total d'entra√Ænement : {end - start:.1f} secondes\")\n",
    "\n",
    "# ‚ûú V√©rification du mod√®le obtenu sur le jeu de test\n",
    "y_proba_grid = grid.predict_proba(X_test)[:, 1]\n",
    "resultat_grid = trouver_seuil_optimal(y_test, y_proba_grid)\n",
    "\n",
    "print(f\"\\nüîç V√©rification sur le test : seuil optimal = {resultat_grid['seuil']:.2f}\")\n",
    "print(f\"Co√ªt m√©tier sur le test = {resultat_grid['co√ªt']}\")\n",
    "\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# BONUS ‚Äì Interpr√©tation locale avec LIME (alternative √† SHAP)\n",
    "# Objectif : donner une explication simple et visuelle d‚Äôune pr√©diction\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "# 1. On installe la librairie LIME (si elle n‚Äôest pas d√©j√† install√©e)\n",
    "# √Ä ex√©cuter une seule fois dans l‚Äôenvironnement Colab ou Jupyter\n",
    "# !pip install lime\n",
    "\n",
    "from lime.lime_tabular import LimeTabularExplainer  # outil d‚Äôexplication locale\n",
    "\n",
    "# 2. On entra√Æne un mod√®le simple (sans pipeline) car LIME ne comprend pas les pipelines non plus\n",
    "modele_lime = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "modele_lime.fit(X_train, y_train)\n",
    "\n",
    "# 3. On cr√©e un \"explainer\" LIME\n",
    "# ‚ûú Il apprend √† expliquer les d√©cisions √† partir des donn√©es d‚Äôentra√Ænement\n",
    "explainer_lime = LimeTabularExplainer(\n",
    "    training_data=X_train.values,         # donn√©es d‚Äôentra√Ænement\n",
    "    feature_names=X_train.columns,        # noms des colonnes pour l'affichage\n",
    "    class_names=['Bon client', 'Mauvais client'],  # nom des classes\n",
    "    mode='classification',                # on fait de la classification (pas de la r√©gression)\n",
    "    verbose=True,                         # pour avoir des infos dans les logs\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 4. On choisit un client √† expliquer dans le jeu de test\n",
    "# ‚ûú Tu peux changer l‚Äôindex si tu veux un autre client\n",
    "index_client = 0\n",
    "client_data = X_test.iloc[index_client].values.reshape(1, -1)  # donn√©es du client\n",
    "\n",
    "# 5. On g√©n√®re l‚Äôexplication LIME\n",
    "explication = explainer_lime.explain_instance(\n",
    "    data_row=X_test.iloc[index_client].values,   # donn√©es du client\n",
    "    predict_fn=modele_lime.predict_proba,        # fonction de pr√©diction du mod√®le\n",
    "    num_features=6                               # on limite √† 6 variables les plus influentes\n",
    ")\n",
    "\n",
    "# 6. On affiche l‚Äôexplication\n",
    "explication.show_in_notebook(show_table=True)\n",
    "\n",
    "# ‚ûú Ce graphique est tr√®s p√©dagogique :\n",
    "# Il montre, pour un seul client, quelles sont les variables qui ont pouss√© le mod√®le √† pr√©dire \"mauvais\" ou \"bon\".\n",
    "# Tr√®s utile √† montrer √† quelqu‚Äôun qui ne conna√Æt pas le machine learning."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
