{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc1ac4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Étape 1 & 2 - Analyse exploratoire + Score métier (projet Home Credit)\n",
    "# Objectif : analyser les données et créer une fonction métier pour évaluer un modèle de scoring crédit\n",
    "\n",
    "# ----------------------\n",
    "# IMPORT DES LIBRAIRIES\n",
    "# ----------------------\n",
    "import pandas as pd  # gestion des données\n",
    "import numpy as np  # calculs numériques\n",
    "import matplotlib.pyplot as plt  # visualisation simple\n",
    "import seaborn as sns  # visualisation plus avancée\n",
    "import missingno as msno  # visualisation des valeurs manquantes\n",
    "import warnings  # pour cacher les avertissements\n",
    "from sklearn.model_selection import train_test_split  # découper les données\n",
    "from sklearn.linear_model import LogisticRegression  # modèle simple et interprétable\n",
    "from sklearn.metrics import confusion_matrix  # évaluer les erreurs de prédiction\n",
    "\n",
    "warnings.filterwarnings('ignore')  # éviter d'afficher les messages de warning inutiles\n",
    "\n",
    "# -------------------------------------\n",
    "# CHARGEMENT DES DONNÉES\n",
    "# -------------------------------------\n",
    "file_path = \"//content/drive/MyDrive/Master AI Engineer/Colab Notebooks/Projet 4/application_train.csv\"\n",
    "\n",
    "# On essaie d'abord avec une virgule, sinon on essaye avec point-virgule\n",
    "try:\n",
    "    df = pd.read_csv(file_path, sep=\",\", encoding=\"utf-8\", low_memory=False)\n",
    "    if df.shape[1] == 1:\n",
    "        raise ValueError(\"Colonnes mal séparées\")\n",
    "except:\n",
    "    df = pd.read_csv(file_path, sep=\";\", encoding=\"utf-8\", low_memory=False)\n",
    "\n",
    "# -------------------------------------\n",
    "# ANALYSE EXPLORATOIRE\n",
    "# -------------------------------------\n",
    "print(\"Aperçu des données :\")\n",
    "print(df.head())\n",
    "print(\"\\nDimensions :\", df.shape)\n",
    "print(\"\\nTypes de données :\")\n",
    "print(df.dtypes.value_counts())\n",
    "print(\"\\nInfos détaillées :\")\n",
    "df.info()\n",
    "\n",
    "# Valeurs manquantes\n",
    "missing = df.isnull().mean().sort_values(ascending=False) * 100\n",
    "missing = missing[missing > 0]\n",
    "if not missing.empty:\n",
    "    plt.figure(figsize=(10, 12))\n",
    "    missing.plot(kind=\"barh\", title=\"Pourcentage de valeurs manquantes par colonne\")\n",
    "    plt.xlabel(\"Pourcentage de valeurs manquantes\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Aucune valeur manquante détectée.\")\n",
    "\n",
    "# Statistiques globales\n",
    "print(\"\\nStatistiques générales :\")\n",
    "print(df.describe().T)\n",
    "\n",
    "# Distribution de la cible (TARGET)\n",
    "if 'TARGET' in df.columns:\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    df['TARGET'].value_counts(normalize=True).plot(kind='bar', color=['skyblue', 'salmon'])\n",
    "    plt.title(\"Répartition de la variable cible (TARGET)\")\n",
    "    plt.xlabel(\"0 = Bon client, 1 = Mauvais client\")\n",
    "    plt.ylabel(\"Proportion\")\n",
    "    plt.show()\n",
    "\n",
    "# -------------------------------------\n",
    "# FEATURE ENGINEERING - NOUVELLES VARIABLES\n",
    "# -------------------------------------\n",
    "print(\"\\nCréation de nouvelles variables :\")\n",
    "if {'AMT_CREDIT', 'AMT_INCOME_TOTAL'}.issubset(df.columns):\n",
    "    df['CREDIT_INCOME_RATIO'] = df['AMT_CREDIT'] / df['AMT_INCOME_TOTAL']\n",
    "    print(\"CREDIT_INCOME_RATIO ajouté.\")\n",
    "\n",
    "if {'AMT_ANNUITY', 'AMT_INCOME_TOTAL'}.issubset(df.columns):\n",
    "    df['ANNUITY_INCOME_RATIO'] = df['AMT_ANNUITY'] / df['AMT_INCOME_TOTAL']\n",
    "    print(\"ANNUITY_INCOME_RATIO ajouté.\")\n",
    "\n",
    "if {'DAYS_EMPLOYED', 'DAYS_BIRTH'}.issubset(df.columns):\n",
    "    df['EMPLOYED_AGE_RATIO'] = df['DAYS_EMPLOYED'] / df['DAYS_BIRTH']\n",
    "    print(\"EMPLOYED_AGE_RATIO ajouté.\")\n",
    "\n",
    "# -------------------------------------\n",
    "# CORRÉLATION AVEC LA CIBLE\n",
    "# -------------------------------------\n",
    "if 'TARGET' in df.columns:\n",
    "    correlations = df.corr(numeric_only=True)['TARGET'].sort_values(ascending=False)\n",
    "    print(\"\\nTop 10 variables les plus corrélées positivement avec le défaut :\")\n",
    "    print(correlations.head(10))\n",
    "    print(\"\\nTop 10 variables les plus corrélées négativement avec le défaut :\")\n",
    "    print(correlations.tail(10))\n",
    "\n",
    "# -------------------------------------\n",
    "# EXPLORATION DES VARIABLES CATÉGORIELLES\n",
    "# -------------------------------------\n",
    "print(\"\\nExploration des variables catégorielles :\")\n",
    "cat_cols = df.select_dtypes(include='object').columns\n",
    "for col in cat_cols:\n",
    "    print(f\"\\n{col} :\")\n",
    "    print(df[col].value_counts(dropna=False).head())\n",
    "\n",
    "# -------------------------------------\n",
    "# ÉTAPE 2 : SCORING MÉTIER ET SEUIL OPTIMAL\n",
    "# -------------------------------------\n",
    "# Nettoyage simple : suppression des NaN, sélection des colonnes numériques uniquement\n",
    "# (pour simplifier, on ne conserve ici que les colonnes sans NaN pour ce premier test)\n",
    "\n",
    "df_model = df.dropna()\n",
    "features = ['AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY', 'CREDIT_INCOME_RATIO', 'ANNUITY_INCOME_RATIO', 'EMPLOYED_AGE_RATIO']\n",
    "X = df_model[features]\n",
    "y = df_model['TARGET']\n",
    "\n",
    "# Découpage des données en 80% train / 20% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Modèle de régression logistique (modèle simple et interprétable)\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Prédiction des probabilités pour le test\n",
    "y_proba = model.predict_proba(X_test)[:, 1]  # on récupère les probabilités d'appartenir à la classe 1\n",
    "\n",
    "# ------------------\n",
    "# Fonction de coût métier\n",
    "# ------------------\n",
    "def cout_metier(y_true, y_pred, cost_fn=10, cost_fp=1):\n",
    "    \"\"\"Calcule le coût total en fonction du nombre de faux négatifs et faux positifs\"\"\"\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    return cost_fn * fn + cost_fp * fp\n",
    "\n",
    "# ------------------\n",
    "# Fonction pour trouver le meilleur seuil\n",
    "# ------------------\n",
    "def trouver_seuil_optimal(y_true, y_proba, seuils=np.arange(0.1, 0.9, 0.01), cost_fn=10, cost_fp=1):\n",
    "    meilleur_seuil = None\n",
    "    meilleur_cout = float('inf')\n",
    "\n",
    "    for seuil in seuils:\n",
    "        y_pred = (y_proba >= seuil).astype(int)\n",
    "        cout = cout_metier(y_true, y_pred, cost_fn, cost_fp)\n",
    "        if cout < meilleur_cout:\n",
    "            meilleur_cout = cout\n",
    "            meilleur_seuil = seuil\n",
    "\n",
    "    return {\"seuil\": meilleur_seuil, \"coût\": meilleur_cout}\n",
    "\n",
    "# Application sur les résultats\n",
    "resultat = trouver_seuil_optimal(y_test, y_proba)\n",
    "print(f\"\\n✅ Seuil optimal = {resultat['seuil']:.2f}, coût total = {resultat['coût']}\")\n",
    "\n",
    "# Affichage graphique du coût selon le seuil choisi\n",
    "seuils = np.arange(0.1, 0.9, 0.01)\n",
    "costs = [cout_metier(y_test, (y_proba >= s).astype(int)) for s in seuils]\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(seuils, costs, label=\"Coût métier\")\n",
    "plt.axvline(resultat['seuil'], color='red', linestyle='--', label='Seuil optimal')\n",
    "plt.xlabel(\"Seuil de classification\")\n",
    "plt.ylabel(\"Coût total (pondéré)\")\n",
    "plt.title(\"Optimisation du seuil de décision\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ✅ Fin de l'étape 2 : modèle interprétable + seuil optimisé selon le coût métier\n",
    "\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# ÉTAPE 3 – Benchmark de modèles : Régression Logistique vs Random Forest\n",
    "# Objectif : tester plusieurs modèles et les comparer en tenant compte :\n",
    "# - du déséquilibre entre bons et mauvais clients\n",
    "# - du coût métier (FN plus grave que FP)\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "# Import de bibliothèques supplémentaires pour cette étape\n",
    "from sklearn.ensemble import RandomForestClassifier  # un modèle plus complexe que la régression\n",
    "from sklearn.model_selection import cross_val_score  # pour faire de la validation croisée\n",
    "from sklearn.pipeline import Pipeline  # permet d’enchaîner plusieurs étapes dans un même objet\n",
    "from sklearn.preprocessing import StandardScaler  # pour normaliser les données\n",
    "from sklearn.metrics import roc_auc_score, roc_curve  # métriques de performance\n",
    "from imblearn.over_sampling import SMOTE  # technique pour équilibrer les classes\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline  # pipeline compatible avec SMOTE\n",
    "\n",
    "# On refait un découpage 80/20 pour bien séparer l'entraînement et le test\n",
    "# stratify permet de garder le même % de mauvais clients dans chaque groupe\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Liste des modèles qu'on veut comparer\n",
    "# Un modèle simple (logistique) et un plus puissant (forêt aléatoire)\n",
    "modeles = [\n",
    "    (\"Régression Logistique\", LogisticRegression(max_iter=1000)),\n",
    "    (\"Random Forest\", RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "]\n",
    "\n",
    "# On prépare une liste pour stocker les résultats de chaque modèle\n",
    "resultats = []\n",
    "\n",
    "# On teste chaque modèle un par un\n",
    "for nom_modele, modele in modeles:\n",
    "    # On crée un \"pipeline\" : c’est un enchaînement d’étapes automatiques\n",
    "    # 1. StandardScaler : normalise les données (utile pour la régression logistique)\n",
    "    # 2. SMOTE : augmente artificiellement les exemples de mauvais clients (classe minoritaire)\n",
    "    # 3. Le modèle choisi\n",
    "    pipeline = ImbPipeline(steps=[\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('smote', SMOTE(random_state=42)),\n",
    "        ('model', modele)\n",
    "    ])\n",
    "\n",
    "    # On évalue la performance du modèle via une validation croisée (5 parties du jeu d'entraînement)\n",
    "    # Cela évite de tirer des conclusions trop hâtives sur un seul découpage\n",
    "    scores_auc = cross_val_score(pipeline, X_train, y_train, scoring='roc_auc', cv=5)\n",
    "    moyenne_auc = np.mean(scores_auc)  # moyenne des AUC obtenues\n",
    "\n",
    "    # On entraîne le pipeline sur tout le jeu d'entraînement\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # On prédit les probabilités pour chaque client du jeu de test\n",
    "    y_proba = pipeline.predict_proba(X_test)[:, 1]  # on garde la proba d’être un mauvais client (classe 1)\n",
    "\n",
    "    # On cherche le seuil de proba qui minimise notre score métier (FN = 10x FP)\n",
    "    resultat_seuil = trouver_seuil_optimal(y_test, y_proba)\n",
    "\n",
    "    # On transforme les proba en prédiction 0 ou 1 avec le bon seuil\n",
    "    y_pred = (y_proba >= resultat_seuil['seuil']).astype(int)\n",
    "\n",
    "    # On mesure la qualité globale via l’AUC (plus c’est proche de 1, mieux c’est)\n",
    "    auc_test = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "    # On enregistre les résultats\n",
    "    resultats.append({\n",
    "        \"Modèle\": nom_modele,\n",
    "        \"AUC Test\": round(auc_test, 3),\n",
    "        \"Seuil Métier\": round(resultat_seuil['seuil'], 2),\n",
    "        \"Coût Métier\": resultat_seuil['coût']\n",
    "    })\n",
    "\n",
    "# On affiche un tableau récapitulatif des performances\n",
    "resultats_df = pd.DataFrame(resultats)\n",
    "print(\"\\n📊 Résumé des performances par modèle :\")\n",
    "print(resultats_df)\n",
    "\n",
    "# BONUS : on trace la courbe ROC pour le meilleur modèle (ici Random Forest)\n",
    "# ROC = Receiver Operating Characteristic\n",
    "# C’est une courbe qui montre le compromis entre :\n",
    "# - vrai positifs (clients mal classés détectés)\n",
    "# - faux positifs (bons clients à qui on refuse à tort)\n",
    "# 3. On réentraîne un modèle Random Forest sur tout l'ensemble d'entraînement pour l'analyse SHAP\n",
    "# On enlève StandardScaler ici car RandomForest n'en a pas besoin\n",
    "best_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "best_pipeline = ImbPipeline([\n",
    "    ('smote', SMOTE(random_state=42)),  # on garde SMOTE pour équilibrer les classes\n",
    "    ('model', best_model)\n",
    "])\n",
    "best_pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_proba_best = best_pipeline.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, _ = roc_curve(y_test, y_proba_best)  # fpr = faux positifs, tpr = vrais positifs\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(fpr, tpr, label=\"ROC - Random Forest\")\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray')  # diagonale : tirage au sort\n",
    "plt.xlabel(\"Taux de faux positifs\")\n",
    "plt.ylabel(\"Taux de vrais positifs\")\n",
    "plt.title(\"Courbe ROC - Random Forest\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ✅ Étape 3 terminée : on a comparé 2 modèles, géré le déséquilibre, mesuré l’AUC et le score métier\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# ÉTAPE 4 – Interprétation du modèle avec SHAP (importance globale et locale)\n",
    "# Objectif : expliquer comment le modèle prend ses décisions\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "# 1. On importe la librairie SHAP (permet d’interpréter comment le modèle raisonne)\n",
    "import shap\n",
    "\n",
    "# 2. On réentraîne un modèle Random Forest tout seul, sans pipeline ni SMOTE\n",
    "# Pourquoi ? Parce que SHAP a besoin du modèle brut (pas d’un pipeline) et des données originales\n",
    "modele_shap = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "modele_shap.fit(X_train, y_train)  # entraînement sur les données d'entraînement d'origine\n",
    "\n",
    "# 3. On crée un \"explainer\" SHAP adapté aux modèles d’arbres (comme RandomForest)\n",
    "explainer = shap.TreeExplainer(modele_shap)\n",
    "\n",
    "# -------------------------------\n",
    "# échantillonnage pour accélérer le calcul SHAP\n",
    "# On sélectionne 200 clients du jeu de test, ça suffit pour l’analyse globale\n",
    "# Cela évite que SHAP prenne plusieurs minutes à tout calculer\n",
    "X_test_sample_df = X_test.sample(n=200, random_state=42).copy()  # on prend un sous-échantillon du test\n",
    "\n",
    "# 4. On calcule les valeurs SHAP avec la nouvelle API\n",
    "shap_values = explainer(X_test_sample_df)\n",
    "\n",
    "# 5. Affichage global des variables les plus influentes\n",
    "shap.summary_plot(shap_values.values, X_test_sample_df, plot_type=\"bar\")\n",
    "\n",
    "#Interpretation locale\n",
    "\n",
    "\n",
    "# Besoin d'aide ici @Gred\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# ÉTAPE 5 – DummyClassifier + Optimisation Random Forest avec GridSearchCV\n",
    "# Objectif : répondre aux attentes restantes du mentor :\n",
    "# - Ajouter un modèle de référence (très basique) appelé \"DummyClassifier\"\n",
    "# - Utiliser GridSearchCV pour tester plusieurs combinaisons de paramètres\n",
    "# - Optimiser le modèle en fonction de notre score métier\n",
    "# - Mesurer aussi l'AUC (qualité globale) et le temps d'exécution\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "from sklearn.dummy import DummyClassifier  # modèle très simple pour établir une baseline\n",
    "from sklearn.metrics import make_scorer  # pour créer une métrique personnalisée\n",
    "from sklearn.model_selection import GridSearchCV  # outil pour tester plusieurs réglages automatiques\n",
    "import time  # pour chronométrer l'entraînement\n",
    "\n",
    "# ➜ On commence par un modèle de base (Dummy) qui prédit toujours la majorité\n",
    "dummy = DummyClassifier(strategy=\"most_frequent\")  # toujours prédire 0\n",
    "dummy.fit(X_train, y_train)\n",
    "y_pred_dummy = dummy.predict(X_test)\n",
    "cout_dummy = cout_metier(y_test, y_pred_dummy)\n",
    "print(f\"\\n📌 Coût métier DummyClassifier (baseline naïve) : {cout_dummy}\")\n",
    "\n",
    "# ➜ On va maintenant définir une fonction personnalisée pour que GridSearch comprenne notre score métier\n",
    "def scoring_metier(y_true, y_proba):\n",
    "    y_pred = (y_proba >= 0.5).astype(int)  # on garde un seuil fixe ici (comme demandé)\n",
    "    return -cout_metier(y_true, y_pred)  # on inverse car GridSearch cherche à *maximiser* le score\n",
    "\n",
    "# make_scorer transforme notre fonction en objet compatible avec sklearn\n",
    "scorer = make_scorer(scoring_metier, needs_proba=True)\n",
    "\n",
    "# ➜ On définit les paramètres qu'on veut tester pour la Random Forest\n",
    "param_grid = {\n",
    "    'model__n_estimators': [50, 100],  # nombre d’arbres dans la forêt\n",
    "    'model__max_depth': [5, 10, None]  # profondeur maximale des arbres\n",
    "}\n",
    "\n",
    "# ➜ Pipeline avec normalisation + SMOTE + RandomForest (comme à l’étape 3)\n",
    "pipeline = ImbPipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('model', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# ➜ On lance GridSearchCV en demandant :\n",
    "# - d’optimiser à la fois notre score métier et l’AUC\n",
    "# - de choisir le modèle avec le *meilleur score métier*\n",
    "grid = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    scoring={'metier': scorer, 'auc': 'roc_auc'},\n",
    "    refit='metier',\n",
    "    cv=5,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "# ➜ On lance l'entraînement complet avec chronomètre\n",
    "start = time.time()\n",
    "grid.fit(X_train, y_train)\n",
    "end = time.time()\n",
    "\n",
    "# ➜ Affichage des meilleurs paramètres et scores associés\n",
    "print(\"\\n✅ Meilleurs paramètres trouvés par GridSearch :\")\n",
    "print(grid.best_params_)\n",
    "print(f\"Score métier moyen (sur le train cross-validé) : {-grid.best_score_:.0f}\")\n",
    "print(f\"Temps total d'entraînement : {end - start:.1f} secondes\")\n",
    "\n",
    "# ➜ Vérification du modèle obtenu sur le jeu de test\n",
    "y_proba_grid = grid.predict_proba(X_test)[:, 1]\n",
    "resultat_grid = trouver_seuil_optimal(y_test, y_proba_grid)\n",
    "\n",
    "print(f\"\\n🔍 Vérification sur le test : seuil optimal = {resultat_grid['seuil']:.2f}\")\n",
    "print(f\"Coût métier sur le test = {resultat_grid['coût']}\")\n",
    "\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# BONUS – Interprétation locale avec LIME (alternative à SHAP)\n",
    "# Objectif : donner une explication simple et visuelle d’une prédiction\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "# 1. On installe la librairie LIME (si elle n’est pas déjà installée)\n",
    "# À exécuter une seule fois dans l’environnement Colab ou Jupyter\n",
    "# !pip install lime\n",
    "\n",
    "from lime.lime_tabular import LimeTabularExplainer  # outil d’explication locale\n",
    "\n",
    "# 2. On entraîne un modèle simple (sans pipeline) car LIME ne comprend pas les pipelines non plus\n",
    "modele_lime = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "modele_lime.fit(X_train, y_train)\n",
    "\n",
    "# 3. On crée un \"explainer\" LIME\n",
    "# ➜ Il apprend à expliquer les décisions à partir des données d’entraînement\n",
    "explainer_lime = LimeTabularExplainer(\n",
    "    training_data=X_train.values,         # données d’entraînement\n",
    "    feature_names=X_train.columns,        # noms des colonnes pour l'affichage\n",
    "    class_names=['Bon client', 'Mauvais client'],  # nom des classes\n",
    "    mode='classification',                # on fait de la classification (pas de la régression)\n",
    "    verbose=True,                         # pour avoir des infos dans les logs\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 4. On choisit un client à expliquer dans le jeu de test\n",
    "# ➜ Tu peux changer l’index si tu veux un autre client\n",
    "index_client = 0\n",
    "client_data = X_test.iloc[index_client].values.reshape(1, -1)  # données du client\n",
    "\n",
    "# 5. On génère l’explication LIME\n",
    "explication = explainer_lime.explain_instance(\n",
    "    data_row=X_test.iloc[index_client].values,   # données du client\n",
    "    predict_fn=modele_lime.predict_proba,        # fonction de prédiction du modèle\n",
    "    num_features=6                               # on limite à 6 variables les plus influentes\n",
    ")\n",
    "\n",
    "# 6. On affiche l’explication\n",
    "explication.show_in_notebook(show_table=True)\n",
    "\n",
    "# ➜ Ce graphique est très pédagogique :\n",
    "# Il montre, pour un seul client, quelles sont les variables qui ont poussé le modèle à prédire \"mauvais\" ou \"bon\".\n",
    "# Très utile à montrer à quelqu’un qui ne connaît pas le machine learning."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
